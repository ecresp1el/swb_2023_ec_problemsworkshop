{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "513171da-0760-4543-937b-18a5d97fc99f",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "\n",
    "\n",
    "## Space\n",
    "The analysis we did during the workshop did not take into account physical space. If neurons near each other have more similar functional properties, and neurons near to one another are more likely to be connected, this effect might be explained just by spatial factors. How big are those effects? Can they explain this shift?\n",
    "\n",
    "There is good evidence that synapses located close to the cell body of equal size are functionally stronger than synapses which are farther from the cell body.  \n",
    "\n",
    "This exercise is longer and more complex than the others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55057c97-1efd-434f-b9ce-7117080c8726",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os \n",
    "import caveclient\n",
    "import scipy\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea417aac-704f-4453-8681-f337bb424878",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "\n",
    "### We will start with recalculating the dataframe from the workshop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "693ea006-bd2e-467d-878d-68b3c90ff91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "import os\n",
    "\n",
    "platstring = platform.platform()\n",
    "if ('Darwin' in platstring) or ('macOS' in platstring):\n",
    "    # macOS \n",
    "    data_root = \"/Volumes/Brain2023/\"\n",
    "elif 'Windows'  in platstring:\n",
    "    # Windows (replace with the drive letter of USB drive)\n",
    "    data_root = \"E:/\"\n",
    "elif ('amzn' in platstring):\n",
    "    # then on Code Ocean\n",
    "    data_root = \"/data/\"\n",
    "else:\n",
    "    # then your own linux platform\n",
    "    # EDIT location where you mounted hard drive\n",
    "    data_root = \"/media/$USERNAME/Brain2023/\"\n",
    "    \n",
    "data_dir = os.path.join(data_root, 'microns_in_silico')\n",
    "\n",
    "# you can just override this if the location of the data varies\n",
    "# data_dir = '/Users/forrestc/Downloads/microns_in_silico/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c02d39",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "\n",
    "### Units dataframe column description\n",
    "\n",
    "* animal_id: uniformally 17797, this experiment has just one animal\n",
    "* scan_session: what day the experiment was done on\n",
    "* scan_idx: what scan on that day was the recording done. NOTE: it is COMBINATION of session and scan which uniquely defines a recording, there are multiple scans with scan_idx =5, 7, 6, and 9. \n",
    "* unit_id: an index on the ROIs recording during that session + scan combination.\n",
    "* row_idx: what is the index of this unit in the response numpy matrix\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ab2872",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "\n",
    "### Coregistration columns\n",
    "* id: a unique index for this coregistration point\n",
    "* target_id: the nucleus ID for this coregistration (target because its a reference to a nucleus)\n",
    "* session: the session (aka scan_session from responses)\n",
    "* scan_idx: the scan index (same as responses)\n",
    "* unit_id: the unit id in the session+scan (same as responses)\n",
    "* field: which of the [1-8] 2d fields the unit came from\n",
    "* residual: a coregistration QC statistic (see paper)\n",
    "* score: a coregistration QC seperation statistic (see paper)\n",
    "* pt_root_id: the segmentation id of the object (possible for one segmentation to have 0,1,2+ nuclei)\n",
    "* pt_position: the x,y,z position of nucleus (in um because of desired_resolution=[1000,1000,1000])\n",
    "* volume: the volume of the nucleus in um^3\n",
    "  \n",
    "Columns you can safely ignore for this exercise\n",
    "* id_ref: the id of the referenced annotation (in this case a nucleus_id so same as target_id)\n",
    "* created: when this was created\n",
    "* created_ref: when the nucleus annotation this references was created\n",
    "* pt_supervoxel_id: the supervoxel underneath this nucleus location\n",
    "* bb_start_position: spots for bounding box start (nan in this dataset)\n",
    "* bb_end_position: spot for bounding boxes end (nan in this dataset)\n",
    "* valid: an internal check variable\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d8f7074c-2d59-45e0-9b82-72b28d101f9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of units_df is:  (104171, 5)\n",
      "The shape of resp is:  (104171, 5000)\n",
      "The shape of coreg_df is:  (13925, 19)\n"
     ]
    }
   ],
   "source": [
    "# we are going to load up the data and prepare the dataframe like we did \n",
    "# in class but with fewer comments\n",
    "\n",
    "# load up the in-silico responses as a pandas dataframe from a numpy array \n",
    "resp=pd.DataFrame(np.load(os.path.join(data_dir, 'nat_resp.npy')))\n",
    "\n",
    "# load up the csv of metadata about the 104171 units\n",
    "units_df = pd.read_csv(os.path.join(data_dir, 'nat_unit.csv'))\n",
    "\n",
    "# set the index to the be the row_idx of the units_df\n",
    "resp.index = units_df['row_idx']\n",
    "\n",
    "# if we are on code ocean, the CAVEsetup helped you make your token an environment variable\n",
    "if 'amzn' in platstring:\n",
    "    client= caveclient.CAVEclient('minnie65_public', auth_token=os.environ['API_SECRET'])\n",
    "else:\n",
    "    # otherwise if you are local, then it should be saved to a file in your harddrive \n",
    "    # that the caveclient knows where to read.\n",
    "    client= caveclient.CAVEclient('minnie65_public')\n",
    "\n",
    "# lets pull out the manual coregistered neurons\n",
    "# desired_resolution describes how many nanometers you want each unit to be\n",
    "# so 1000,1000,1000 gives positions in microns for x,y and z\n",
    "coreg_df = client.materialize.query_table('coregistration_manual_v3', desired_resolution=[1000,1000,1000])\n",
    "\n",
    "#print the shape of units_df\n",
    "print('The shape of units_df is: ', units_df.shape)\n",
    "\n",
    "#print the shape of resp\n",
    "print('The shape of resp is: ', resp.shape)\n",
    "\n",
    "#print the shape of coreg_df\n",
    "print('The shape of coreg_df is: ', coreg_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1300dcc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>animal_id</th>\n",
       "      <th>scan_session</th>\n",
       "      <th>scan_idx</th>\n",
       "      <th>unit_id</th>\n",
       "      <th>row_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17797</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17797</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17797</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17797</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17797</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   animal_id  scan_session  scan_idx  unit_id  row_idx\n",
       "0      17797             4         7        1        0\n",
       "1      17797             4         7        3        1\n",
       "2      17797             4         7        4        2\n",
       "3      17797             4         7        5        3\n",
       "4      17797             4         7        6        4"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "units_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "01eb8591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of coreg_in_silico is:  (12094, 22)\n"
     ]
    }
   ],
   "source": [
    "# lets merge these dataframes so we get the row_idx of each coregistered unit\n",
    "# we merge on the corresponding columns, however scan was called something\n",
    "# slightly different in one csv vs the CAVE table\n",
    "coreg_in_silico=pd.merge(units_df, coreg_df, # left and right dataframes\n",
    "         left_on=['scan_session', 'scan_idx', 'unit_id'], # left columns\n",
    "          right_on=['session','scan_idx', 'unit_id']) # right columns\n",
    "\n",
    "#print the shape of coreg_in_silico\n",
    "print('The shape of coreg_in_silico is: ', coreg_in_silico.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5c26bbec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>animal_id</th>\n",
       "      <th>scan_session</th>\n",
       "      <th>scan_idx</th>\n",
       "      <th>unit_id</th>\n",
       "      <th>row_idx</th>\n",
       "      <th>id_ref</th>\n",
       "      <th>created_ref</th>\n",
       "      <th>valid_ref</th>\n",
       "      <th>volume</th>\n",
       "      <th>pt_supervoxel_id</th>\n",
       "      <th>...</th>\n",
       "      <th>created</th>\n",
       "      <th>valid</th>\n",
       "      <th>target_id</th>\n",
       "      <th>session</th>\n",
       "      <th>field</th>\n",
       "      <th>residual</th>\n",
       "      <th>score</th>\n",
       "      <th>pt_position</th>\n",
       "      <th>bb_start_position</th>\n",
       "      <th>bb_end_position</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17797</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>648</td>\n",
       "      <td>517</td>\n",
       "      <td>516506</td>\n",
       "      <td>2020-09-28 22:44:43.650751+00:00</td>\n",
       "      <td>t</td>\n",
       "      <td>276.767375</td>\n",
       "      <td>105487283075464806</td>\n",
       "      <td>...</td>\n",
       "      <td>2023-04-05 22:38:59.933339+00:00</td>\n",
       "      <td>t</td>\n",
       "      <td>516506</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>6.181260</td>\n",
       "      <td>11.443982</td>\n",
       "      <td>[1184.832, 378.752, 632.12]</td>\n",
       "      <td>[nan, nan, nan]</td>\n",
       "      <td>[nan, nan, nan]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17797</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>662</td>\n",
       "      <td>530</td>\n",
       "      <td>452329</td>\n",
       "      <td>2020-09-28 22:45:02.852190+00:00</td>\n",
       "      <td>t</td>\n",
       "      <td>311.618437</td>\n",
       "      <td>101758289725398433</td>\n",
       "      <td>...</td>\n",
       "      <td>2023-04-05 22:39:40.786518+00:00</td>\n",
       "      <td>t</td>\n",
       "      <td>452329</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5.422790</td>\n",
       "      <td>12.006788</td>\n",
       "      <td>[1076.992, 395.328, 735.28]</td>\n",
       "      <td>[nan, nan, nan]</td>\n",
       "      <td>[nan, nan, nan]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17797</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>665</td>\n",
       "      <td>533</td>\n",
       "      <td>451461</td>\n",
       "      <td>2020-09-28 22:41:51.543636+00:00</td>\n",
       "      <td>t</td>\n",
       "      <td>263.504036</td>\n",
       "      <td>102531727972419182</td>\n",
       "      <td>...</td>\n",
       "      <td>2023-04-05 22:39:41.400499+00:00</td>\n",
       "      <td>t</td>\n",
       "      <td>451461</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1.280470</td>\n",
       "      <td>15.025886</td>\n",
       "      <td>[1099.456, 376.256, 881.84]</td>\n",
       "      <td>[nan, nan, nan]</td>\n",
       "      <td>[nan, nan, nan]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17797</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>671</td>\n",
       "      <td>539</td>\n",
       "      <td>420222</td>\n",
       "      <td>2020-09-28 22:45:01.445495+00:00</td>\n",
       "      <td>t</td>\n",
       "      <td>309.882880</td>\n",
       "      <td>100491446037118564</td>\n",
       "      <td>...</td>\n",
       "      <td>2023-04-05 22:39:27.234487+00:00</td>\n",
       "      <td>t</td>\n",
       "      <td>420222</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.704028</td>\n",
       "      <td>21.035651</td>\n",
       "      <td>[1039.744, 389.44, 678.96]</td>\n",
       "      <td>[nan, nan, nan]</td>\n",
       "      <td>[nan, nan, nan]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17797</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>682</td>\n",
       "      <td>549</td>\n",
       "      <td>420058</td>\n",
       "      <td>2020-09-28 22:44:36.438460+00:00</td>\n",
       "      <td>t</td>\n",
       "      <td>267.026432</td>\n",
       "      <td>98661652329244694</td>\n",
       "      <td>...</td>\n",
       "      <td>2023-04-05 22:36:19.482289+00:00</td>\n",
       "      <td>t</td>\n",
       "      <td>420058</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>9.648310</td>\n",
       "      <td>2.794440</td>\n",
       "      <td>[985.792, 383.424, 634.92]</td>\n",
       "      <td>[nan, nan, nan]</td>\n",
       "      <td>[nan, nan, nan]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   animal_id  scan_session  scan_idx  unit_id  row_idx  id_ref  \\\n",
       "0      17797             4         7      648      517  516506   \n",
       "1      17797             4         7      662      530  452329   \n",
       "2      17797             4         7      665      533  451461   \n",
       "3      17797             4         7      671      539  420222   \n",
       "4      17797             4         7      682      549  420058   \n",
       "\n",
       "                       created_ref valid_ref      volume    pt_supervoxel_id  \\\n",
       "0 2020-09-28 22:44:43.650751+00:00         t  276.767375  105487283075464806   \n",
       "1 2020-09-28 22:45:02.852190+00:00         t  311.618437  101758289725398433   \n",
       "2 2020-09-28 22:41:51.543636+00:00         t  263.504036  102531727972419182   \n",
       "3 2020-09-28 22:45:01.445495+00:00         t  309.882880  100491446037118564   \n",
       "4 2020-09-28 22:44:36.438460+00:00         t  267.026432   98661652329244694   \n",
       "\n",
       "   ...                          created  valid target_id session  field  \\\n",
       "0  ... 2023-04-05 22:38:59.933339+00:00      t    516506       4      2   \n",
       "1  ... 2023-04-05 22:39:40.786518+00:00      t    452329       4      2   \n",
       "2  ... 2023-04-05 22:39:41.400499+00:00      t    451461       4      2   \n",
       "3  ... 2023-04-05 22:39:27.234487+00:00      t    420222       4      2   \n",
       "4  ... 2023-04-05 22:36:19.482289+00:00      t    420058       4      2   \n",
       "\n",
       "   residual      score                  pt_position  bb_start_position  \\\n",
       "0  6.181260  11.443982  [1184.832, 378.752, 632.12]    [nan, nan, nan]   \n",
       "1  5.422790  12.006788  [1076.992, 395.328, 735.28]    [nan, nan, nan]   \n",
       "2  1.280470  15.025886  [1099.456, 376.256, 881.84]    [nan, nan, nan]   \n",
       "3  0.704028  21.035651   [1039.744, 389.44, 678.96]    [nan, nan, nan]   \n",
       "4  9.648310   2.794440   [985.792, 383.424, 634.92]    [nan, nan, nan]   \n",
       "\n",
       "   bb_end_position  \n",
       "0  [nan, nan, nan]  \n",
       "1  [nan, nan, nan]  \n",
       "2  [nan, nan, nan]  \n",
       "3  [nan, nan, nan]  \n",
       "4  [nan, nan, nan]  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coreg_in_silico.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3d81ed7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>animal_id</th>\n",
       "      <th>scan_session</th>\n",
       "      <th>scan_idx</th>\n",
       "      <th>unit_id</th>\n",
       "      <th>row_idx</th>\n",
       "      <th>id_ref</th>\n",
       "      <th>created_ref</th>\n",
       "      <th>valid_ref</th>\n",
       "      <th>volume</th>\n",
       "      <th>...</th>\n",
       "      <th>created</th>\n",
       "      <th>valid</th>\n",
       "      <th>target_id</th>\n",
       "      <th>session</th>\n",
       "      <th>field</th>\n",
       "      <th>residual</th>\n",
       "      <th>score</th>\n",
       "      <th>pt_position</th>\n",
       "      <th>bb_start_position</th>\n",
       "      <th>bb_end_position</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>17797</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>648</td>\n",
       "      <td>517</td>\n",
       "      <td>516506</td>\n",
       "      <td>2020-09-28 22:44:43.650751+00:00</td>\n",
       "      <td>t</td>\n",
       "      <td>276.767375</td>\n",
       "      <td>...</td>\n",
       "      <td>2023-04-05 22:38:59.933339+00:00</td>\n",
       "      <td>t</td>\n",
       "      <td>516506</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>6.181260</td>\n",
       "      <td>11.443982</td>\n",
       "      <td>[1184.832, 378.752, 632.12]</td>\n",
       "      <td>[nan, nan, nan]</td>\n",
       "      <td>[nan, nan, nan]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>17797</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>662</td>\n",
       "      <td>530</td>\n",
       "      <td>452329</td>\n",
       "      <td>2020-09-28 22:45:02.852190+00:00</td>\n",
       "      <td>t</td>\n",
       "      <td>311.618437</td>\n",
       "      <td>...</td>\n",
       "      <td>2023-04-05 22:39:40.786518+00:00</td>\n",
       "      <td>t</td>\n",
       "      <td>452329</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5.422790</td>\n",
       "      <td>12.006788</td>\n",
       "      <td>[1076.992, 395.328, 735.28]</td>\n",
       "      <td>[nan, nan, nan]</td>\n",
       "      <td>[nan, nan, nan]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>17797</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>665</td>\n",
       "      <td>533</td>\n",
       "      <td>451461</td>\n",
       "      <td>2020-09-28 22:41:51.543636+00:00</td>\n",
       "      <td>t</td>\n",
       "      <td>263.504036</td>\n",
       "      <td>...</td>\n",
       "      <td>2023-04-05 22:39:41.400499+00:00</td>\n",
       "      <td>t</td>\n",
       "      <td>451461</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1.280470</td>\n",
       "      <td>15.025886</td>\n",
       "      <td>[1099.456, 376.256, 881.84]</td>\n",
       "      <td>[nan, nan, nan]</td>\n",
       "      <td>[nan, nan, nan]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>17797</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>671</td>\n",
       "      <td>539</td>\n",
       "      <td>420222</td>\n",
       "      <td>2020-09-28 22:45:01.445495+00:00</td>\n",
       "      <td>t</td>\n",
       "      <td>309.882880</td>\n",
       "      <td>...</td>\n",
       "      <td>2023-04-05 22:39:27.234487+00:00</td>\n",
       "      <td>t</td>\n",
       "      <td>420222</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.704028</td>\n",
       "      <td>21.035651</td>\n",
       "      <td>[1039.744, 389.44, 678.96]</td>\n",
       "      <td>[nan, nan, nan]</td>\n",
       "      <td>[nan, nan, nan]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>17797</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>682</td>\n",
       "      <td>549</td>\n",
       "      <td>420058</td>\n",
       "      <td>2020-09-28 22:44:36.438460+00:00</td>\n",
       "      <td>t</td>\n",
       "      <td>267.026432</td>\n",
       "      <td>...</td>\n",
       "      <td>2023-04-05 22:36:19.482289+00:00</td>\n",
       "      <td>t</td>\n",
       "      <td>420058</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>9.648310</td>\n",
       "      <td>2.794440</td>\n",
       "      <td>[985.792, 383.424, 634.92]</td>\n",
       "      <td>[nan, nan, nan]</td>\n",
       "      <td>[nan, nan, nan]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  animal_id  scan_session  scan_idx  unit_id  row_idx  id_ref  \\\n",
       "0      0      17797             4         7      648      517  516506   \n",
       "1      1      17797             4         7      662      530  452329   \n",
       "2      2      17797             4         7      665      533  451461   \n",
       "3      3      17797             4         7      671      539  420222   \n",
       "4      4      17797             4         7      682      549  420058   \n",
       "\n",
       "                       created_ref valid_ref      volume  ...  \\\n",
       "0 2020-09-28 22:44:43.650751+00:00         t  276.767375  ...   \n",
       "1 2020-09-28 22:45:02.852190+00:00         t  311.618437  ...   \n",
       "2 2020-09-28 22:41:51.543636+00:00         t  263.504036  ...   \n",
       "3 2020-09-28 22:45:01.445495+00:00         t  309.882880  ...   \n",
       "4 2020-09-28 22:44:36.438460+00:00         t  267.026432  ...   \n",
       "\n",
       "                           created  valid  target_id session field  residual  \\\n",
       "0 2023-04-05 22:38:59.933339+00:00      t     516506       4     2  6.181260   \n",
       "1 2023-04-05 22:39:40.786518+00:00      t     452329       4     2  5.422790   \n",
       "2 2023-04-05 22:39:41.400499+00:00      t     451461       4     2  1.280470   \n",
       "3 2023-04-05 22:39:27.234487+00:00      t     420222       4     2  0.704028   \n",
       "4 2023-04-05 22:36:19.482289+00:00      t     420058       4     2  9.648310   \n",
       "\n",
       "       score                  pt_position  bb_start_position  bb_end_position  \n",
       "0  11.443982  [1184.832, 378.752, 632.12]    [nan, nan, nan]  [nan, nan, nan]  \n",
       "1  12.006788  [1076.992, 395.328, 735.28]    [nan, nan, nan]  [nan, nan, nan]  \n",
       "2  15.025886  [1099.456, 376.256, 881.84]    [nan, nan, nan]  [nan, nan, nan]  \n",
       "3  21.035651   [1039.744, 389.44, 678.96]    [nan, nan, nan]  [nan, nan, nan]  \n",
       "4   2.794440   [985.792, 383.424, 634.92]    [nan, nan, nan]  [nan, nan, nan]  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reset the index to make sure that we have the index\n",
    "coreg_in_silico.reset_index(inplace=True) \n",
    "\n",
    "coreg_in_silico.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3a56cbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will pull out the responses to the coregistered units\n",
    "# by using the row_idx that was provided in the metadata\n",
    "coreg_resp = resp.loc[coreg_in_silico.row_idx,:] # pull out the responses to the coregistered units by using the row_idx that was provided in the metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9abc08e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now with a reduced set of units, we can calculate the Pearson correlation\n",
    "# between their responses\n",
    "corr_M = np.corrcoef(coreg_resp.values) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd2f205-4d1c-4f1f-874a-f8aa427984d5",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "\n",
    "However this time lets make a dataframe that contains all the correlations\n",
    "but also the nucleus IDs of both sides of the correlation\n",
    "and then merge in the nucleus positions so we can measure the\n",
    "soma to soma distance of that correlation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "685161ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>animal_id</th>\n",
       "      <th>scan_session</th>\n",
       "      <th>scan_idx</th>\n",
       "      <th>unit_id</th>\n",
       "      <th>row_idx</th>\n",
       "      <th>id</th>\n",
       "      <th>created</th>\n",
       "      <th>valid</th>\n",
       "      <th>target_id</th>\n",
       "      <th>...</th>\n",
       "      <th>score</th>\n",
       "      <th>id_ref</th>\n",
       "      <th>created_ref</th>\n",
       "      <th>valid_ref</th>\n",
       "      <th>volume</th>\n",
       "      <th>pt_supervoxel_id</th>\n",
       "      <th>pt_root_id</th>\n",
       "      <th>pt_position</th>\n",
       "      <th>bb_start_position</th>\n",
       "      <th>bb_end_position</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>17797</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>648</td>\n",
       "      <td>517</td>\n",
       "      <td>2043</td>\n",
       "      <td>2023-04-05 22:38:59.933339+00:00</td>\n",
       "      <td>t</td>\n",
       "      <td>516506</td>\n",
       "      <td>...</td>\n",
       "      <td>11.443982</td>\n",
       "      <td>516506</td>\n",
       "      <td>2020-09-28 22:44:43.650751+00:00</td>\n",
       "      <td>t</td>\n",
       "      <td>276.767375</td>\n",
       "      <td>105487283075464806</td>\n",
       "      <td>864691135348268503</td>\n",
       "      <td>[1184.832, 378.752, 632.12]</td>\n",
       "      <td>[nan, nan, nan]</td>\n",
       "      <td>[nan, nan, nan]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>17797</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>662</td>\n",
       "      <td>530</td>\n",
       "      <td>10173</td>\n",
       "      <td>2023-04-05 22:39:40.786518+00:00</td>\n",
       "      <td>t</td>\n",
       "      <td>452329</td>\n",
       "      <td>...</td>\n",
       "      <td>12.006788</td>\n",
       "      <td>452329</td>\n",
       "      <td>2020-09-28 22:45:02.852190+00:00</td>\n",
       "      <td>t</td>\n",
       "      <td>311.618437</td>\n",
       "      <td>101758289725398433</td>\n",
       "      <td>864691135700505634</td>\n",
       "      <td>[1076.992, 395.328, 735.28]</td>\n",
       "      <td>[nan, nan, nan]</td>\n",
       "      <td>[nan, nan, nan]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>17797</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>665</td>\n",
       "      <td>533</td>\n",
       "      <td>10871</td>\n",
       "      <td>2023-04-05 22:39:41.400499+00:00</td>\n",
       "      <td>t</td>\n",
       "      <td>451461</td>\n",
       "      <td>...</td>\n",
       "      <td>15.025886</td>\n",
       "      <td>451461</td>\n",
       "      <td>2020-09-28 22:41:51.543636+00:00</td>\n",
       "      <td>t</td>\n",
       "      <td>263.504036</td>\n",
       "      <td>102531727972419182</td>\n",
       "      <td>864691135776919981</td>\n",
       "      <td>[1099.456, 376.256, 881.84]</td>\n",
       "      <td>[nan, nan, nan]</td>\n",
       "      <td>[nan, nan, nan]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>17797</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>671</td>\n",
       "      <td>539</td>\n",
       "      <td>8088</td>\n",
       "      <td>2023-04-05 22:39:27.234487+00:00</td>\n",
       "      <td>t</td>\n",
       "      <td>420222</td>\n",
       "      <td>...</td>\n",
       "      <td>21.035651</td>\n",
       "      <td>420222</td>\n",
       "      <td>2020-09-28 22:45:01.445495+00:00</td>\n",
       "      <td>t</td>\n",
       "      <td>309.882880</td>\n",
       "      <td>100491446037118564</td>\n",
       "      <td>864691135472842290</td>\n",
       "      <td>[1039.744, 389.44, 678.96]</td>\n",
       "      <td>[nan, nan, nan]</td>\n",
       "      <td>[nan, nan, nan]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>17797</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>682</td>\n",
       "      <td>549</td>\n",
       "      <td>1480</td>\n",
       "      <td>2023-04-05 22:36:19.482289+00:00</td>\n",
       "      <td>t</td>\n",
       "      <td>420058</td>\n",
       "      <td>...</td>\n",
       "      <td>2.794440</td>\n",
       "      <td>420058</td>\n",
       "      <td>2020-09-28 22:44:36.438460+00:00</td>\n",
       "      <td>t</td>\n",
       "      <td>267.026432</td>\n",
       "      <td>98661652329244694</td>\n",
       "      <td>864691135349237975</td>\n",
       "      <td>[985.792, 383.424, 634.92]</td>\n",
       "      <td>[nan, nan, nan]</td>\n",
       "      <td>[nan, nan, nan]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>17797</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>686</td>\n",
       "      <td>553</td>\n",
       "      <td>1106</td>\n",
       "      <td>2023-04-05 22:36:19.163677+00:00</td>\n",
       "      <td>t</td>\n",
       "      <td>420403</td>\n",
       "      <td>...</td>\n",
       "      <td>10.747270</td>\n",
       "      <td>420403</td>\n",
       "      <td>2020-09-28 22:42:27.376760+00:00</td>\n",
       "      <td>t</td>\n",
       "      <td>304.421274</td>\n",
       "      <td>99999071321769531</td>\n",
       "      <td>864691135345445279</td>\n",
       "      <td>[1025.28, 394.048, 779.04]</td>\n",
       "      <td>[nan, nan, nan]</td>\n",
       "      <td>[nan, nan, nan]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>17797</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>690</td>\n",
       "      <td>557</td>\n",
       "      <td>692</td>\n",
       "      <td>2023-04-05 22:38:09.793823+00:00</td>\n",
       "      <td>t</td>\n",
       "      <td>389167</td>\n",
       "      <td>...</td>\n",
       "      <td>2.665841</td>\n",
       "      <td>389167</td>\n",
       "      <td>2020-09-28 22:41:51.558752+00:00</td>\n",
       "      <td>t</td>\n",
       "      <td>346.720829</td>\n",
       "      <td>98099595997372919</td>\n",
       "      <td>864691135334495209</td>\n",
       "      <td>[969.024, 409.92, 713.08]</td>\n",
       "      <td>[nan, nan, nan]</td>\n",
       "      <td>[nan, nan, nan]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>17797</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>691</td>\n",
       "      <td>558</td>\n",
       "      <td>779</td>\n",
       "      <td>2023-04-05 22:38:09.863476+00:00</td>\n",
       "      <td>t</td>\n",
       "      <td>389164</td>\n",
       "      <td>...</td>\n",
       "      <td>5.579912</td>\n",
       "      <td>389164</td>\n",
       "      <td>2020-09-28 22:45:11.330457+00:00</td>\n",
       "      <td>t</td>\n",
       "      <td>332.952207</td>\n",
       "      <td>98029227252939503</td>\n",
       "      <td>864691135688112096</td>\n",
       "      <td>[967.36, 408.832, 705.32]</td>\n",
       "      <td>[nan, nan, nan]</td>\n",
       "      <td>[nan, nan, nan]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>17797</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>702</td>\n",
       "      <td>568</td>\n",
       "      <td>3658</td>\n",
       "      <td>2023-04-05 22:39:03.611226+00:00</td>\n",
       "      <td>t</td>\n",
       "      <td>389183</td>\n",
       "      <td>...</td>\n",
       "      <td>12.026620</td>\n",
       "      <td>389183</td>\n",
       "      <td>2020-09-28 22:45:05.663650+00:00</td>\n",
       "      <td>t</td>\n",
       "      <td>317.565665</td>\n",
       "      <td>96551414972912364</td>\n",
       "      <td>864691135234029401</td>\n",
       "      <td>[924.032, 406.784, 727.96]</td>\n",
       "      <td>[nan, nan, nan]</td>\n",
       "      <td>[nan, nan, nan]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>17797</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>703</td>\n",
       "      <td>569</td>\n",
       "      <td>4908</td>\n",
       "      <td>2023-04-05 22:39:07.425785+00:00</td>\n",
       "      <td>t</td>\n",
       "      <td>389458</td>\n",
       "      <td>...</td>\n",
       "      <td>8.079086</td>\n",
       "      <td>389458</td>\n",
       "      <td>2020-09-28 22:44:30.630418+00:00</td>\n",
       "      <td>t</td>\n",
       "      <td>258.159903</td>\n",
       "      <td>97676765526421836</td>\n",
       "      <td>864691135478783942</td>\n",
       "      <td>[957.44, 390.912, 844.6]</td>\n",
       "      <td>[nan, nan, nan]</td>\n",
       "      <td>[nan, nan, nan]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  animal_id  scan_session  scan_idx  unit_id  row_idx     id  \\\n",
       "0      0      17797             4         7      648      517   2043   \n",
       "1      1      17797             4         7      662      530  10173   \n",
       "2      2      17797             4         7      665      533  10871   \n",
       "3      3      17797             4         7      671      539   8088   \n",
       "4      4      17797             4         7      682      549   1480   \n",
       "5      5      17797             4         7      686      553   1106   \n",
       "6      6      17797             4         7      690      557    692   \n",
       "7      7      17797             4         7      691      558    779   \n",
       "8      8      17797             4         7      702      568   3658   \n",
       "9      9      17797             4         7      703      569   4908   \n",
       "\n",
       "                           created valid  target_id  ...      score  id_ref  \\\n",
       "0 2023-04-05 22:38:59.933339+00:00     t     516506  ...  11.443982  516506   \n",
       "1 2023-04-05 22:39:40.786518+00:00     t     452329  ...  12.006788  452329   \n",
       "2 2023-04-05 22:39:41.400499+00:00     t     451461  ...  15.025886  451461   \n",
       "3 2023-04-05 22:39:27.234487+00:00     t     420222  ...  21.035651  420222   \n",
       "4 2023-04-05 22:36:19.482289+00:00     t     420058  ...   2.794440  420058   \n",
       "5 2023-04-05 22:36:19.163677+00:00     t     420403  ...  10.747270  420403   \n",
       "6 2023-04-05 22:38:09.793823+00:00     t     389167  ...   2.665841  389167   \n",
       "7 2023-04-05 22:38:09.863476+00:00     t     389164  ...   5.579912  389164   \n",
       "8 2023-04-05 22:39:03.611226+00:00     t     389183  ...  12.026620  389183   \n",
       "9 2023-04-05 22:39:07.425785+00:00     t     389458  ...   8.079086  389458   \n",
       "\n",
       "                       created_ref  valid_ref      volume    pt_supervoxel_id  \\\n",
       "0 2020-09-28 22:44:43.650751+00:00          t  276.767375  105487283075464806   \n",
       "1 2020-09-28 22:45:02.852190+00:00          t  311.618437  101758289725398433   \n",
       "2 2020-09-28 22:41:51.543636+00:00          t  263.504036  102531727972419182   \n",
       "3 2020-09-28 22:45:01.445495+00:00          t  309.882880  100491446037118564   \n",
       "4 2020-09-28 22:44:36.438460+00:00          t  267.026432   98661652329244694   \n",
       "5 2020-09-28 22:42:27.376760+00:00          t  304.421274   99999071321769531   \n",
       "6 2020-09-28 22:41:51.558752+00:00          t  346.720829   98099595997372919   \n",
       "7 2020-09-28 22:45:11.330457+00:00          t  332.952207   98029227252939503   \n",
       "8 2020-09-28 22:45:05.663650+00:00          t  317.565665   96551414972912364   \n",
       "9 2020-09-28 22:44:30.630418+00:00          t  258.159903   97676765526421836   \n",
       "\n",
       "           pt_root_id                  pt_position  bb_start_position  \\\n",
       "0  864691135348268503  [1184.832, 378.752, 632.12]    [nan, nan, nan]   \n",
       "1  864691135700505634  [1076.992, 395.328, 735.28]    [nan, nan, nan]   \n",
       "2  864691135776919981  [1099.456, 376.256, 881.84]    [nan, nan, nan]   \n",
       "3  864691135472842290   [1039.744, 389.44, 678.96]    [nan, nan, nan]   \n",
       "4  864691135349237975   [985.792, 383.424, 634.92]    [nan, nan, nan]   \n",
       "5  864691135345445279   [1025.28, 394.048, 779.04]    [nan, nan, nan]   \n",
       "6  864691135334495209    [969.024, 409.92, 713.08]    [nan, nan, nan]   \n",
       "7  864691135688112096    [967.36, 408.832, 705.32]    [nan, nan, nan]   \n",
       "8  864691135234029401   [924.032, 406.784, 727.96]    [nan, nan, nan]   \n",
       "9  864691135478783942     [957.44, 390.912, 844.6]    [nan, nan, nan]   \n",
       "\n",
       "   bb_end_position  \n",
       "0  [nan, nan, nan]  \n",
       "1  [nan, nan, nan]  \n",
       "2  [nan, nan, nan]  \n",
       "3  [nan, nan, nan]  \n",
       "4  [nan, nan, nan]  \n",
       "5  [nan, nan, nan]  \n",
       "6  [nan, nan, nan]  \n",
       "7  [nan, nan, nan]  \n",
       "8  [nan, nan, nan]  \n",
       "9  [nan, nan, nan]  \n",
       "\n",
       "[10 rows x 23 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coreg_in_silico.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ed2818d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['index', 'animal_id', 'scan_session', 'scan_idx', 'unit_id', 'row_idx',\n",
      "       'id', 'created', 'valid', 'target_id', 'session', 'field', 'residual',\n",
      "       'score', 'id_ref', 'created_ref', 'valid_ref', 'volume',\n",
      "       'pt_supervoxel_id', 'pt_root_id', 'pt_position', 'bb_start_position',\n",
      "       'bb_end_position'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#print the column names \n",
    "print(coreg_in_silico.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "634a8f14-0b52-45d6-ae52-981a85271de7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[516506 452329 451461 ... 454429 391240 454708]\n"
     ]
    }
   ],
   "source": [
    "# get an array of the nucleus IDs of each row/column of the corr_M\n",
    "# this should be in the 'target_id' column\n",
    "array_of_nucleus_ids = coreg_in_silico['target_id'].values \n",
    "\n",
    "\n",
    "# use the row and column indices to get an array of nucleus IDs on each side of the correlation matrix \n",
    "\n",
    "\n",
    "# use fancy indexing to pull out the correlation values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb97013-04d4-4be0-b8e6-ad4cdd5c169c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct a dataframe using these 3 columns\n",
    "# hint use a a dictionary to name the columns\n",
    "# and include \"copy=False\" to avoid blowing up memory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c3b790-23c2-46fc-84d2-dd2a4f8c9f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the nucleus positions dataframe\n",
    "# converting the positions to microns\n",
    "# and using standard transform to adjust them to be flat\n",
    "nuc_df = client.materialize.query_view('nucleus_detection_lookup_v1', \n",
    "                                        select_columns = ['id', 'pt_root_id', 'pt_position'],\n",
    "                                        desired_resolution=[1,1,1])\n",
    "from standard_transform.datasets import minnie_transform_nm\n",
    "tform=minnie_transform_nm()\n",
    "nuc_df['pt_position']=tform.apply(nuc_df.pt_position)\n",
    "nuc_df['pt_position']=nuc_df.pt_position.apply(np.array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3daefaff-24ef-4dee-a18a-06de984ac1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge on the pre and post positions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784a2a2f-3fca-4b0f-9371-7dee8572e8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the first few rows of your dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ce8386-bf64-4b23-84be-fdc667911179",
   "metadata": {},
   "outputs": [],
   "source": [
    "# measure the distance between the soma of nuc1 and nuc2\n",
    "\n",
    "# measure the distance also in x,z only.. this is along the surface of cortex\n",
    "\n",
    "# hints: look at np.vstack, np.linalg.norm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fbe35f3-d16a-4fd0-bab5-e5cdf656647c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b48e731-8b34-4ace-9bb1-47c9cc63e7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out distances of <2 microns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6ab0c5-271a-4202-b8c0-8592f466e89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using binned statistic, lets measure the avg C as a function of euclidean distance\n",
    "\n",
    "# make up some distance bins from 2-250 microns\n",
    "\n",
    "\n",
    "# use scipy.stats.binned_statistic\n",
    "# to measure correlation as a function of distance\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08a1f06-5d8f-4933-9864-fcfe4098bf28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc797ce-eafd-43a2-9d35-f335aec98698",
   "metadata": {},
   "outputs": [],
   "source": [
    "# what about using the cortical distance\n",
    "# use the same bins\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acec3b14-de00-4688-a818-069e8681cfc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a plot of mean Correlation and std error bars a function of distance\n",
    "# put both distances on same plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1831962b-68e4-4211-a4d7-60cda36adfdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a plot of how many pairs fall in each of these distance bins\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b023a2f-8c99-4b59-b524-28ecffae2b4b",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "\n",
    "#### Thought question\n",
    "\n",
    "What explains these curves? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fb3eb3a3-45ba-4285-ab11-baf5224cffaa",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nuc_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 15\u001b[0m\n\u001b[1;32m      9\u001b[0m all_syn_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_pickle(workshop2file)\n\u001b[1;32m     11\u001b[0m \u001b[39m# lets merge on the pre and post-synaptic positions of these connections\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \n\u001b[1;32m     13\u001b[0m \u001b[39m# renaming the positions as pre and post depending on how we did the merge\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[39m# and drop the duplicate id columns\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m all_syn_dfm\u001b[39m=\u001b[39mall_syn_df\u001b[39m.\u001b[39mmerge(nuc_df[[\u001b[39m'\u001b[39m\u001b[39mid\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mpt_position\u001b[39m\u001b[39m'\u001b[39m]], left_on\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mpre_nuc_id\u001b[39m\u001b[39m'\u001b[39m, right_on\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mid\u001b[39m\u001b[39m'\u001b[39m)\\\n\u001b[1;32m     16\u001b[0m \u001b[39m.\u001b[39mrename({\u001b[39m'\u001b[39m\u001b[39mpt_position\u001b[39m\u001b[39m'\u001b[39m:\u001b[39m'\u001b[39m\u001b[39mpre_pt_position\u001b[39m\u001b[39m'\u001b[39m}, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\\\n\u001b[1;32m     17\u001b[0m \u001b[39m.\u001b[39mmerge(nuc_df[[\u001b[39m'\u001b[39m\u001b[39mid\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mpt_position\u001b[39m\u001b[39m'\u001b[39m]], left_on\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mpost_nuc_id\u001b[39m\u001b[39m'\u001b[39m, right_on\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mid\u001b[39m\u001b[39m'\u001b[39m)\\\n\u001b[1;32m     18\u001b[0m \u001b[39m.\u001b[39mrename({\u001b[39m'\u001b[39m\u001b[39mpt_position\u001b[39m\u001b[39m'\u001b[39m:\u001b[39m'\u001b[39m\u001b[39mpost_pt_position\u001b[39m\u001b[39m'\u001b[39m}, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\\\n\u001b[1;32m     19\u001b[0m \u001b[39m.\u001b[39mdrop([\u001b[39m'\u001b[39m\u001b[39mid_x\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mid_y\u001b[39m\u001b[39m'\u001b[39m], axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     21\u001b[0m \u001b[39m# now lets merge in the neurons that are coregistered with responses\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \n\u001b[1;32m     23\u001b[0m \u001b[39m# we have to drop duplicates to avoid the few cells that were coregistered twice \u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[39m# being double counted\u001b[39;00m\n\u001b[1;32m     25\u001b[0m all_syn_dfm2\u001b[39m=\u001b[39mall_syn_dfm\u001b[39m.\u001b[39mmerge(coreg_in_silico[[\u001b[39m'\u001b[39m\u001b[39mindex\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mtarget_id\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mscan_session\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mscan_idx\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mfield\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39munit_id\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mscore\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mresidual\u001b[39m\u001b[39m'\u001b[39m]],\n\u001b[1;32m     26\u001b[0m                   left_on\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mpre_nuc_id\u001b[39m\u001b[39m'\u001b[39m, \n\u001b[1;32m     27\u001b[0m                   right_on\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtarget_id\u001b[39m\u001b[39m'\u001b[39m)\\\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[39m.\u001b[39mdrop([\u001b[39m'\u001b[39m\u001b[39mtarget_id_pre\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mtarget_id_post\u001b[39m\u001b[39m'\u001b[39m],axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\\\n\u001b[1;32m     33\u001b[0m \u001b[39m.\u001b[39mdrop_duplicates(subset\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mpre_nuc_id\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mpost_nuc_id\u001b[39m\u001b[39m'\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nuc_df' is not defined"
     ]
    }
   ],
   "source": [
    "# make the same plot but for connected pairs of neurons\n",
    "# first lets reconstruct the dataframe from the workshop\n",
    "# we need this code to work in solutions directory\n",
    "# and one up..\n",
    "if 'solutions' in os.getcwd():\n",
    "    workshop2file = '../../workshop2/all_prf_coreg_conn_v661.pkl'\n",
    "else:\n",
    "    workshop2file = '../workshop2/all_prf_coreg_conn_v661.pkl'\n",
    "all_syn_df = pd.read_pickle(workshop2file)\n",
    "\n",
    "# lets merge on the pre and post-synaptic positions of these connections\n",
    "\n",
    "# renaming the positions as pre and post depending on how we did the merge\n",
    "# and drop the duplicate id columns\n",
    "all_syn_dfm=all_syn_df.merge(nuc_df[['id', 'pt_position']], left_on='pre_nuc_id', right_on='id')\\\n",
    ".rename({'pt_position':'pre_pt_position'}, axis=1)\\\n",
    ".merge(nuc_df[['id', 'pt_position']], left_on='post_nuc_id', right_on='id')\\\n",
    ".rename({'pt_position':'post_pt_position'}, axis=1)\\\n",
    ".drop(['id_x', 'id_y'], axis=1)\n",
    "\n",
    "# now lets merge in the neurons that are coregistered with responses\n",
    "\n",
    "# we have to drop duplicates to avoid the few cells that were coregistered twice \n",
    "# being double counted\n",
    "all_syn_dfm2=all_syn_dfm.merge(coreg_in_silico[['index','target_id', 'scan_session', 'scan_idx', 'field','unit_id', 'score', 'residual']],\n",
    "                  left_on='pre_nuc_id', \n",
    "                  right_on='target_id')\\\n",
    ".merge(coreg_in_silico[['index','target_id', 'scan_session', 'scan_idx', 'field','unit_id','score', 'residual']],\n",
    "                  left_on='post_nuc_id', \n",
    "                  right_on='target_id',\n",
    "                  suffixes=['_pre', '_post'])\\\n",
    ".drop(['target_id_pre', 'target_id_post'],axis=1)\\\n",
    ".drop_duplicates(subset=['pre_nuc_id', 'post_nuc_id'])\n",
    "all_syn_dfm2\n",
    "\n",
    "# now use fancy indexing to pull out the correlation associated with each of these connections\n",
    "all_syn_dfm2['C']=corr_M[all_syn_dfm2.index_pre, all_syn_dfm2.index_post]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e102d7-56e0-4461-aa86-32953a4778f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets cut the dataframe down to just the columns we need\n",
    "df_conn=all_syn_dfm2[['pre_nuc_id', 'post_nuc_id', 'n_syn', 'sum_size', 'C', 'pre_pt_position', 'post_pt_position']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec39ee1a-c83a-4abc-97d9-11bcabfe408f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_conn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12fb70b9-6586-442d-a20a-b5f3f48aae33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the intersoma distance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8706a2-c302-44e2-b63d-c48b1b063823",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out the soma distances of <2 microns\n",
    "# to discount the double roi cells\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0211be69-34ad-43ac-ac61-63f4ca19534a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use scipy.stats.binned_statistic\n",
    "# to measure correlation as a function of distance for connected\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b21f82-8fd9-4a32-bdeb-5a4b5b0ab37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  plot both curves for connected and all paris on top of one another\n",
    "# make a plot of mean Correlation and std error bars a function of distance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804393dd-3612-426b-bf23-8de0aee02781",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  plot both curves for connected and all paris on top of one another\n",
    "# make a plot of mean Correlation and std error bars a function of distance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51498fe7-c813-4a94-a931-eb67eb9e812c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot how many connected pairs are in each distance bin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054e7ad7-d718-4b26-b637-cd131d71883f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot how many are connected in a cortical distance bin\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f59b91e-b411-4ba7-89f7-a86a977f963f",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "\n",
    "#### Thought questions\n",
    "\n",
    "What explains the difference between this curve and the overall distribution of pairs of recorded ROIs? \n",
    "\n",
    "Does this curve match your expectation for what cortical connectivity should look like?\n",
    "\n",
    "If space explains a lot of the differences between connected and unconnected pairs,\n",
    "what does that mean?\n",
    "\n",
    "How does it affect your interpretation of the effects?\n",
    "\n",
    "Are there spatial effects that go beyond just soma to soma distance that would be important to control for in order to interpret a finding as being evidence for a particular mechanism?\n",
    "\n",
    "#### Extensions/Project Ideas\n",
    "\n",
    "Can you make a model which resamples the all pairs to match the spatial distributions found in the connected dataset?  Are the results significant compared to that null model?\n",
    "\n",
    "Does this explain the variation seen in the single cell effects.. that some cells have closer and farther away targets in the brain?\n",
    "\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
