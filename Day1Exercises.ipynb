{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7606efdc",
   "metadata": {},
   "source": [
    "\n",
    "![Image](./resources/cropped-SummerWorkshop_Header.png)\n",
    "\n",
    "<h1 align=\"center\">Encoding </h1> \n",
    "<h2 align=\"center\"> Day 1, Exercises. SWDB 2023 </h2> \n",
    "\n",
    "<h3 align=\"center\">Monday, August 21, 2023</h3> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a83611",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #DFF0D8; \">\n",
    "There are more excersizes here than you can likely do in a afternoon. That said, please try a few of them - this is your first chance to use you newly minted Python skills to dig into a new data set! \n",
    "    \n",
    "Remember, if you get stuck there are TAs all around to help you. Don't waste time beating your head against a problem. We are here to help!\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "398f59d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to import these modules to get started\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import platform\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0dc4bc2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set file location based on platform. \n",
    "platstring = platform.platform()\n",
    "if ('Darwin' in platstring) or ('macOS' in platstring):\n",
    "    # macOS \n",
    "    data_root = \"/Volumes/Brain2023/\"\n",
    "elif 'Windows'  in platstring:\n",
    "    # Windows (replace with the drive letter of USB drive)\n",
    "    data_root = \"E:/\"\n",
    "elif ('amzn' in platstring):\n",
    "    # then on Code Ocean\n",
    "    data_root = \"/data/\"\n",
    "else:\n",
    "    # then your own linux platform\n",
    "    # EDIT location where \n",
    "    # you mounted hard drive\n",
    "    data_root = \"/media/$USERNAME/Brain2023/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d785cc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from allensdk.core.brain_observatory_cache import BrainObservatoryCache\n",
    "\n",
    "manifest_file = os.path.join(data_root,'allen-brain-observatory/visual-coding-2p/manifest.json')\n",
    "\n",
    "boc = BrainObservatoryCache(manifest_file=manifest_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563c0130",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #DFF0D8; \">\n",
    "\n",
    "<h2> Exercise 1: Explore direction tuning. </h2>\n",
    "     <p>\n",
    "   \n",
    "The workshops earlier today looked deeply at only a few examples of direction tuning in excitatory cells in primary visual cortex (Visp). Try digging a little deeper into the Brain Observatory data. \n",
    "</p>   \n",
    "\n",
    "<p>\n",
    "There is abolutly no right answer to this exercise, and everyone will end up with different adventure. \n",
    "</p>   \n",
    "    \n",
    "Some ideas include:\n",
    "<ul>\n",
    "  <li>Try a different brain area. </li>\n",
    "  <li>Or try a different Cre line. Maybe an inhibitory line would be particularly interesting?</li>\n",
    "  <li>Try adifferent imaging  depth.</li> \n",
    "  <li>Find a session with more running, or one where the mouse never runs.  </li> \n",
    "</ul>\n",
    "   \n",
    "<p> \n",
    "Do these areas/cre line/depths have direction tuning? Does it look different than in this mornings workshops? Are cells in the population more or less reliable?\n",
    "</p>\n",
    "    \n",
    "<p>   \n",
    "There is a very large search space. One strategy might be to team up with someone else so you can systematically try and compare a few different combinations.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58c37d8",
   "metadata": {},
   "source": [
    "To get you started, here is a quick refresher on how to query sessions in the data. We will go over two ways, one using the primarily the AllenSDK and the other outsourcing some of your queries to Pandas.\n",
    "\n",
    "Recall: the BrainObservatoryCache will tell you all of the avalible brain areas, cre lines, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "525e7eb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['VISal', 'VISam', 'VISl', 'VISp', 'VISpm', 'VISrl']\n",
      "['Cux2-CreERT2', 'Emx1-IRES-Cre', 'Fezf2-CreER', 'Nr5a1-Cre', 'Ntsr1-Cre_GN220', 'Pvalb-IRES-Cre', 'Rbp4-Cre_KL100', 'Rorb-IRES2-Cre', 'Scnn1a-Tg3-Cre', 'Slc17a7-IRES2-Cre', 'Sst-IRES-Cre', 'Tlx3-Cre_PL56', 'Vip-IRES-Cre']\n"
     ]
    }
   ],
   "source": [
    "print(boc.get_all_targeted_structures())\n",
    "print(boc.get_all_cre_lines())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199be141",
   "metadata": {},
   "source": [
    "You can then use the Cache object to query for your session(s) of interest. \n",
    "\n",
    "If you unsure where to start, we recomend choosing an SST-IRES-Cre line. Here, expression of GCaMP is driven in SST-positive interneurons, a type of inhibitory cell. This will form a nice juxdeposition to the excitatory cell line use in this morning's example. \n",
    "\n",
    "One note: you may notice that there are relativly few inhibitory neurons in any given session. This is because there are proportionally fewer inhibitory cells in cortex, and therefore fewer in any experiments field of view."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b35581ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>imaging_depth</th>\n",
       "      <th>targeted_structure</th>\n",
       "      <th>cre_line</th>\n",
       "      <th>reporter_line</th>\n",
       "      <th>acquisition_age_days</th>\n",
       "      <th>experiment_container_id</th>\n",
       "      <th>session_type</th>\n",
       "      <th>donor_name</th>\n",
       "      <th>specimen_name</th>\n",
       "      <th>fail_eye_tracking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>603763073</td>\n",
       "      <td>325</td>\n",
       "      <td>VISpm</td>\n",
       "      <td>Sst-IRES-Cre</td>\n",
       "      <td>Ai148(TIT2L-GC6f-ICL-tTA2)</td>\n",
       "      <td>102</td>\n",
       "      <td>603763385</td>\n",
       "      <td>three_session_A</td>\n",
       "      <td>323528</td>\n",
       "      <td>Sst-IRES-Cre;Ai148(CAM)-323528</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>639117196</td>\n",
       "      <td>375</td>\n",
       "      <td>VISpm</td>\n",
       "      <td>Sst-IRES-Cre</td>\n",
       "      <td>Ai148(TIT2L-GC6f-ICL-tTA2)</td>\n",
       "      <td>97</td>\n",
       "      <td>639117194</td>\n",
       "      <td>three_session_A</td>\n",
       "      <td>340377</td>\n",
       "      <td>Sst-IRES-Cre;Ai148-340377</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>639251932</td>\n",
       "      <td>375</td>\n",
       "      <td>VISpm</td>\n",
       "      <td>Sst-IRES-Cre</td>\n",
       "      <td>Ai148(TIT2L-GC6f-ICL-tTA2)</td>\n",
       "      <td>96</td>\n",
       "      <td>639251930</td>\n",
       "      <td>three_session_A</td>\n",
       "      <td>340854</td>\n",
       "      <td>Sst-IRES-Cre;Ai148-340854</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>599909878</td>\n",
       "      <td>300</td>\n",
       "      <td>VISpm</td>\n",
       "      <td>Sst-IRES-Cre</td>\n",
       "      <td>Ai148(TIT2L-GC6f-ICL-tTA2)</td>\n",
       "      <td>111</td>\n",
       "      <td>599920955</td>\n",
       "      <td>three_session_A</td>\n",
       "      <td>315562</td>\n",
       "      <td>Sst-IRES-Cre;Ai148(CAM)-315562</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>603188560</td>\n",
       "      <td>275</td>\n",
       "      <td>VISpm</td>\n",
       "      <td>Sst-IRES-Cre</td>\n",
       "      <td>Ai148(TIT2L-GC6f-ICL-tTA2)</td>\n",
       "      <td>103</td>\n",
       "      <td>602397921</td>\n",
       "      <td>three_session_A</td>\n",
       "      <td>321822</td>\n",
       "      <td>Sst-IRES-Cre;Ai148(CAM)-321822</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  imaging_depth targeted_structure      cre_line  \\\n",
       "0  603763073            325              VISpm  Sst-IRES-Cre   \n",
       "1  639117196            375              VISpm  Sst-IRES-Cre   \n",
       "2  639251932            375              VISpm  Sst-IRES-Cre   \n",
       "3  599909878            300              VISpm  Sst-IRES-Cre   \n",
       "4  603188560            275              VISpm  Sst-IRES-Cre   \n",
       "\n",
       "                reporter_line  acquisition_age_days  experiment_container_id  \\\n",
       "0  Ai148(TIT2L-GC6f-ICL-tTA2)                   102                603763385   \n",
       "1  Ai148(TIT2L-GC6f-ICL-tTA2)                    97                639117194   \n",
       "2  Ai148(TIT2L-GC6f-ICL-tTA2)                    96                639251930   \n",
       "3  Ai148(TIT2L-GC6f-ICL-tTA2)                   111                599920955   \n",
       "4  Ai148(TIT2L-GC6f-ICL-tTA2)                   103                602397921   \n",
       "\n",
       "      session_type donor_name                   specimen_name  \\\n",
       "0  three_session_A     323528  Sst-IRES-Cre;Ai148(CAM)-323528   \n",
       "1  three_session_A     340377       Sst-IRES-Cre;Ai148-340377   \n",
       "2  three_session_A     340854       Sst-IRES-Cre;Ai148-340854   \n",
       "3  three_session_A     315562  Sst-IRES-Cre;Ai148(CAM)-315562   \n",
       "4  three_session_A     321822  Sst-IRES-Cre;Ai148(CAM)-321822   \n",
       "\n",
       "   fail_eye_tracking  \n",
       "0               True  \n",
       "1               True  \n",
       "2               True  \n",
       "3              False  \n",
       "4              False  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sessions_list = boc.get_ophys_experiments(stimuli=['drifting_gratings'],\n",
    "                                                            cre_lines = ['SSt-IRES-Cre'],\n",
    "                                                            targeted_structures=['VISpm'])\n",
    "sessions_table = pd.DataFrame(sessions_list)\n",
    "sessions_table.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca95cc76",
   "metadata": {},
   "source": [
    "From here, you can select a session ID to try using the code from this morning!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "17eebbc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of sessions with Rbp4 in VISp:  21\n",
      "The number of sessions with failed eye tracking:  6\n",
      "The ids of the sessions with failed eye tracking:  [502962794 638754561 502665019 502741583 637672042 637115675]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>imaging_depth</th>\n",
       "      <th>targeted_structure</th>\n",
       "      <th>cre_line</th>\n",
       "      <th>reporter_line</th>\n",
       "      <th>acquisition_age_days</th>\n",
       "      <th>experiment_container_id</th>\n",
       "      <th>session_type</th>\n",
       "      <th>donor_name</th>\n",
       "      <th>specimen_name</th>\n",
       "      <th>fail_eye_tracking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>652340572</td>\n",
       "      <td>375</td>\n",
       "      <td>VISp</td>\n",
       "      <td>Rbp4-Cre_KL100</td>\n",
       "      <td>Ai93(TITL-GCaMP6f)</td>\n",
       "      <td>105</td>\n",
       "      <td>649401934</td>\n",
       "      <td>three_session_B</td>\n",
       "      <td>352161</td>\n",
       "      <td>Rbp4-Cre_KL100;Camk2a-tTA;Ai93-352161</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>649401936</td>\n",
       "      <td>375</td>\n",
       "      <td>VISp</td>\n",
       "      <td>Rbp4-Cre_KL100</td>\n",
       "      <td>Ai93(TITL-GCaMP6f)</td>\n",
       "      <td>89</td>\n",
       "      <td>649401934</td>\n",
       "      <td>three_session_A</td>\n",
       "      <td>352161</td>\n",
       "      <td>Rbp4-Cre_KL100;Camk2a-tTA;Ai93-352161</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>591537010</td>\n",
       "      <td>375</td>\n",
       "      <td>VISp</td>\n",
       "      <td>Rbp4-Cre_KL100</td>\n",
       "      <td>Ai93(TITL-GCaMP6f)</td>\n",
       "      <td>139</td>\n",
       "      <td>588503721</td>\n",
       "      <td>three_session_C2</td>\n",
       "      <td>301125</td>\n",
       "      <td>Rbp4-Cre_KL100;Camk2a-tTA;Ai93-301125</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>571494829</td>\n",
       "      <td>375</td>\n",
       "      <td>VISp</td>\n",
       "      <td>Rbp4-Cre_KL100</td>\n",
       "      <td>Ai93(TITL-GCaMP6f)</td>\n",
       "      <td>122</td>\n",
       "      <td>571137444</td>\n",
       "      <td>three_session_C2</td>\n",
       "      <td>288600</td>\n",
       "      <td>Rbp4-Cre;Camk2a-tTA;Ai93-288600</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>571137446</td>\n",
       "      <td>375</td>\n",
       "      <td>VISp</td>\n",
       "      <td>Rbp4-Cre_KL100</td>\n",
       "      <td>Ai93(TITL-GCaMP6f)</td>\n",
       "      <td>117</td>\n",
       "      <td>571137444</td>\n",
       "      <td>three_session_A</td>\n",
       "      <td>288600</td>\n",
       "      <td>Rbp4-Cre;Camk2a-tTA;Ai93-288600</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  imaging_depth targeted_structure        cre_line  \\\n",
       "0  652340572            375               VISp  Rbp4-Cre_KL100   \n",
       "1  649401936            375               VISp  Rbp4-Cre_KL100   \n",
       "2  591537010            375               VISp  Rbp4-Cre_KL100   \n",
       "3  571494829            375               VISp  Rbp4-Cre_KL100   \n",
       "5  571137446            375               VISp  Rbp4-Cre_KL100   \n",
       "\n",
       "        reporter_line  acquisition_age_days  experiment_container_id  \\\n",
       "0  Ai93(TITL-GCaMP6f)                   105                649401934   \n",
       "1  Ai93(TITL-GCaMP6f)                    89                649401934   \n",
       "2  Ai93(TITL-GCaMP6f)                   139                588503721   \n",
       "3  Ai93(TITL-GCaMP6f)                   122                571137444   \n",
       "5  Ai93(TITL-GCaMP6f)                   117                571137444   \n",
       "\n",
       "       session_type donor_name                          specimen_name  \\\n",
       "0   three_session_B     352161  Rbp4-Cre_KL100;Camk2a-tTA;Ai93-352161   \n",
       "1   three_session_A     352161  Rbp4-Cre_KL100;Camk2a-tTA;Ai93-352161   \n",
       "2  three_session_C2     301125  Rbp4-Cre_KL100;Camk2a-tTA;Ai93-301125   \n",
       "3  three_session_C2     288600        Rbp4-Cre;Camk2a-tTA;Ai93-288600   \n",
       "5   three_session_A     288600        Rbp4-Cre;Camk2a-tTA;Ai93-288600   \n",
       "\n",
       "   fail_eye_tracking  \n",
       "0              False  \n",
       "1              False  \n",
       "2              False  \n",
       "3              False  \n",
       "5              False  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "sessions_with_spont_list_rbp4 = boc.get_ophys_experiments(stimuli=['spontaneous'], \n",
    "                                                cre_lines = ['Rbp4-Cre_KL100'], \n",
    "                                                targeted_structures=['VISp'])\n",
    "#print the number of sessions\n",
    "print('The number of sessions with Rbp4 in VISp: ', len(sessions_with_spont_list_rbp4) )\n",
    "\n",
    "#create a dataframe of the sessions\n",
    "sessions_table = pd.DataFrame(sessions_with_spont_list_rbp4)\n",
    "\n",
    "#show the first 5 rows of the dataframe\n",
    "sessions_table.head()\n",
    "\n",
    "#determine the number of fail_eye_tracking sessions in the dataframe and print the number and isolate the session ids\n",
    "fail_eye_tracking = sessions_table[sessions_table.fail_eye_tracking == True]\n",
    "print('The number of sessions with failed eye tracking: ', len(fail_eye_tracking))\n",
    "fail_eye_tracking_ids = fail_eye_tracking.id.values\n",
    "print('The ids of the sessions with failed eye tracking: ', fail_eye_tracking_ids)\n",
    "\n",
    "#create the dataframe of the sessions without failed eye tracking, and rename it to sessions_table\n",
    "sessions_table_without_failedeyetracking = sessions_table[sessions_table.fail_eye_tracking == False]\n",
    "\n",
    "#show the first 5 rows of the dataframe\n",
    "sessions_table_without_failedeyetracking.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543f52cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cb72cbb5",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #DFF0D8; \">\n",
    "\n",
    "<h2> Exercise 2: To df/f or not to df/f, that is the question. </h2>\n",
    "\n",
    "In the workshop, we chose to use detected Ca2+ events to build our receptive fields and analyse our data. Did this matter? How might this have changed our results?\n",
    "    \n",
    "<p> To test this, find a few cells with known tuning behavior. Try building a tuning curve using both the df/f traces and the detected event magnitudes. What does this decision do to the tuning curves? In what situtations might this distinction matter more or less? </p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f92968",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b2273b5f",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #DFF0D8; \">\n",
    "\n",
    "<h2> Exercise 3: What else might be encoded in visual cortex?</h2>\n",
    "   \n",
    "    <p>\n",
    "Remeber, these mice saw more then just driting grating stimuli! Lets see if we can learn about the spatial selectivity of these cells, that is, we can ask whether cells encode the spatial location of stimuli.\n",
    "   \n",
    "        <p>\n",
    "To do this, we will use a stimulus set known as \"locally sparse noise.\" Here, mice were shown movies consisting of a mostly grey screen with non-neighboring (locally sparse) black and white pixels positioned randomly (noise) on the screen. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d9a90a",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #DFF0D8; \">\n",
    "\n",
    "<h2> Exercise 3a: Get the dataset and look at the noise stimulus</h2>\n",
    "    \n",
    "First, lets get the session containing the locally sparse noise and plot a frame of the stimulus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c9a9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions_list = boc.get_ophys_experiments(experiment_container_ids= [637998953],\n",
    "                                          stimuli=['locally_sparse_noise_8deg'],)\n",
    "sessions_table = pd.DataFrame(sessions_list)\n",
    "sessions_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5140d3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "session_id = sessions_table.id.values[0]\n",
    "data_set = boc.get_ophys_experiment_data(ophys_experiment_id=sessions_table.id.values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd6b74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the stimulus table\n",
    "stim_table = data_set.get_stimulus_table('locally_sparse_noise_8deg')\n",
    "stim_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38236e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the stimulus movie\n",
    "# It is called the \"stimulus template\"\n",
    "stimulus_template = data_set.get_stimulus_template('locally_sparse_noise_8deg')\n",
    "stimulus_template.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335fe5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a single frame\n",
    "fig,ax = plt.subplots()\n",
    "ax.imshow(stimulus_template[0],cmap= 'Greys')\n",
    "ax.set_xlabel('X pixels')\n",
    "ax.set_ylabel('Y pixels')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc64f74e",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #DFF0D8; \">\n",
    "\n",
    "<h2> Exercise 3b: Get per-trial responses  </h2>\n",
    "    \n",
    "Here, we need to make a decision about how to bin time for each trial. How large should the trial window be? Should it extend beyond the lenght of the trail? Why? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "74fa2bb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of cells in session 502962794 is 79\n",
      "The number of cells in session 638754561 is 20\n",
      "The number of cells in session 502665019 is 71\n",
      "The number of cells in session 502741583 is 76\n",
      "The number of cells in session 637672042 is 15\n",
      "The number of cells in session 637115675 is 23\n"
     ]
    }
   ],
   "source": [
    "# create a function that iterates the input ids which is a list of session ids \n",
    "# and prints the number of cells in each session\n",
    "def print_number_of_cells(input_ids): \n",
    "    for session_id in input_ids: #for each session id in the list of session ids\n",
    "        data_set = boc.get_ophys_experiment_data(ophys_experiment_id=session_id) #get the data set for that session id\n",
    "        print('The number of cells in session ' + str(session_id) + ' is ' + str(data_set.get_cell_specimen_ids().shape[0]))\n",
    "        \n",
    "#call the function on the sessions with failed eye tracking\n",
    "print_number_of_cells(fail_eye_tracking_ids)\n",
    "\n",
    "#create a function that plots the mean response of a a randome cell to a stimulus "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852c8cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a window. \n",
    "# We will (somewhat arbitrarily) start with 15 frames, or about 1/2 secons\n",
    "window = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4919ffa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the average response amplitude on each trial\n",
    "responses = np.zeros((len(stim_table),num_cells))\n",
    "for ii,row in stim_table.iterrows():\n",
    "    for cc in range(num_cells):\n",
    "         responses[ii,cc] = events[cc,row.start:row.start+window].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf53284",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #DFF0D8; \">\n",
    "\n",
    "<h2> Exercise 3c: Build a design matrix using this stimulus</h2>\n",
    "    \n",
    "We can represent each frame in the 2 dimension image by \"flattening\" the image into the vector. Stacking these vectors will allow us to build a design matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5521ac1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the shape of one frame?\n",
    "stimulus_template[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6275d3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What does this look like flattened?\n",
    "flat_stim = stimulus_template[0].flatten()\n",
    "flat_stim.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a6ed79",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots()\n",
    "ax.plot(flat_stim)\n",
    "ax.set_xlabel('pixel id')\n",
    "ax.set_ylabel('pixel intensity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38452ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do this for every trial\n",
    "design_matrix = np.zeros((len(stim_table),len(flat_stim)))\n",
    "for ii in range(len(stim_table)):\n",
    "    design_matrix[ii,:] = stimulus_template[ii].flatten()\n",
    "design_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87de85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For ease of interpetability, change white values to 1s, greys to 0, and blacks to -1:\n",
    "design_matrix[design_matrix==255] = 1\n",
    "design_matrix[design_matrix==0] = -1\n",
    "design_matrix[design_matrix==127]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4dd0e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that worked\n",
    "fig,ax = plt.subplots()\n",
    "plt.plot(design_matrix[0,:])\n",
    "ax.set_xlabel('pixel id')\n",
    "ax.set_ylabel('pixel intensity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30627273",
   "metadata": {},
   "outputs": [],
   "source": [
    "# what does this look like?\n",
    "# Its too big to plot the whole thing, but lets look at a section; \n",
    "# The first 150 rows is a good start\n",
    "fig,ax = plt.subplots()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e37d5dd",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #DFF0D8; \">\n",
    "\n",
    "<h2> Exercise 3d: Split your data into training and testing sets</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb13d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import model fitting code\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e6d56d",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #DFF0D8; \">\n",
    "\n",
    "<h2> Exercise 3e: Fit a model. </h2>\n",
    "    \n",
    "<p>\n",
    "We recomend cell_specimine_id  = 662194111, but try several!\n",
    "   \n",
    "    <p>\n",
    "Try plotting the model coefficients. Because we flattened the stimulus frame early, you will need to use np.reshape to get the vectorized coefficients back into the shape of the original frame in the stimulus template. What does the pattern tell you? \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b95070",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2fb6c29d",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #DFF0D8; \">\n",
    "\n",
    "<h2> Exercise 3f: Fit a model for all the cells in the session</h2>\n",
    "\n",
    "<p> Plot the coefficients for the most and least reliable models. What do you notice about the population of responses?\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082f2e97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3bd1573e",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #DFF0D8; \">\n",
    "\n",
    "<h2> Exercise 4: What else might be encoded in visual cortex?</h2>\n",
    "    \n",
    "Try to see if you can find a neuron that reliable encodes another of the presented stimulus sets. \n",
    "    \n",
    "Some places to try:\n",
    "<ul>\n",
    "  <li>Tempral frequencies: We filtered this mornings data to select only one temporal frequncy. Was there temporal frequency tuning as well?</li>\n",
    "  <li>Natural Scenes: Scenes were shown more than one time. Are there cells with consistant responses across presentations? </li>\n",
    "  <li>Natural Movies: Are there cells with a consistant response timecourse as a move unfolds?</li>\n",
    "</ul>\n",
    "    \n",
    "Answering each of these questions will require thoughts about the assumtions you make about the data. For example, what time window makes sense to use? Given the timecourse of Ca2+ data, should you include time after a stimulus for short presentations? Similarly, how might you bin data in a natural movie? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6282aba0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "14220888",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #DFF0D8; \">\n",
    "\n",
    "<h2> Exercise 5: The Bootstrap - Another way to assess reliability</h2>\n",
    "  \n",
    "<p>\n",
    "In this morning's tutiorial, we saw the use of one particular statistic, the direction selectivity index, or DSI. We also saw the key problem with DSI and many similar metrics - they will tell you how selective a cell is (on average) to a particular stimulus, but not how reliable this selectivity is.\n",
    "    </p>   \n",
    "<p>\n",
    "One approach to address this problem is to ask the hypotheical, \"What would this metric be for my cell if my cell's repsonses were independent of the stimulus?\" By breaking the relationship between a stimulus and a cells response, we can get sense of whether our observed metric was higher than what we might have expected by chance. \n",
    "    </p>    \n",
    "\n",
    "<p>\n",
    "We can break this relationship by shuffling the cell's response relative to whatever value in the stimulus we want to test. Because we have already collected the data, we can shuffle the same data set many times to build a distribtuion of \"null\" values, and look at where our observed value falls in this distribuition. \n",
    "    </p>\n",
    "    \n",
    "\n",
    "<p>\n",
    "This is a version of a technique known as \"bootstraping,\" because our resampling allows us to \"pull our data up by its bootstraps\" - resample our data without needing to collect more.\n",
    "</p>\n",
    "    \n",
    "    \n",
    "<p>\n",
    "While bootstrapping does not explicilty quanitify reliability, it is an indirect way of assessing it. If a cell has a reliable response to a particular stimulus, shuffling the stimulus identity will greatly reduce the DSI. On th\n",
    "\n",
    "<p>\n",
    "Here, lets try some bootstrapping using the data from this mornings session. Convienently, we have already saved these data in a way that will make them easy to work with for this exercise:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9abf614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from workshop\n",
    "import os\n",
    "\n",
    "session_id = 637998955\n",
    "load_loc = os.path.join('/scratch','Workshop1')\n",
    "\n",
    "orientation = np.load(os.path.join(load_loc,str(session_id)+'_orientation.npy'))\n",
    "temp_freq = np.load(os.path.join(load_loc,str(session_id)+'_temp_freq.npy'))\n",
    "mean_response_all = np.load(os.path.join(load_loc,str(session_id)+'_mean_response_all.npy'))\n",
    "\n",
    "#filter for temp_freq = 1:\n",
    "orientation = orientation[temp_freq==1]\n",
    "mean_response_all = mean_response_all[temp_freq==1,:]\n",
    "temp_freq = temp_freq[temp_freq==1]\n",
    "\n",
    "# Get all orientations\n",
    "orientations = np.unique(orientation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78902401",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a fuction that computes DSI\n",
    "def dsi(ori_vals,tuning):\n",
    "    \"\"\"\n",
    "    Computes the direction selectivity of a cell. \n",
    "    De Vries 2019\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ori_vals : float array of length N\n",
    "         List of orientation values, in degrees\n",
    "    tuning : float array of length N\n",
    "        Each value the (averaged) response of the cell at a different\n",
    "        orientation, in the same order as ori_vals\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dsi : float\n",
    "        Direction selectivity Index\n",
    "    \"\"\"\n",
    "    # Find the index of the max response\n",
    "    pref_idx = np.argmax(tuning) \n",
    "    # Find the prefered direction\n",
    "    pref_dir = ori_vals[pref_idx] \n",
    "    # and prefered response.\n",
    "    R_pref = tuning[pref_idx]\n",
    "    \n",
    "    # Null direction is opposing, so 180 degress from prefered\n",
    "    # Here % sign is the modulus, so wraps around 360.\n",
    "    null_dir = (pref_dir +180)%360 \n",
    "    # Find the index of the null direction\n",
    "    null_idx = list(ori_vals).index(null_dir)\n",
    "    # Find the null response\n",
    "    R_null = tuning[null_idx]\n",
    "    \n",
    "    return (R_pref-R_null)/(R_pref+R_null)\n",
    "\n",
    "def compute_tuning_curve(mean_response,orientation,orientations):\n",
    "    \"\"\"\n",
    "    Compute the tuning curve for a set of reponses and orientations\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    mean_response : np.array\n",
    "        The mean response for each stimulus\n",
    "    orientation : np.array\n",
    "        Orientation of each stimulus\n",
    "    orientations: np.array\n",
    "        All orientations to compute tuning over\n",
    "        Useful when a subset of orientations are needed.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    tuning : np.array\n",
    "        mean response at each orientation\n",
    "    stdev: np.array \n",
    "        Standard deviation of responses at each orientation\n",
    "    \"\"\"\n",
    "    tuning = np.zeros(orientations.shape)\n",
    "    stdev = np.zeros(orientations.shape)\n",
    "    for ii,ori in enumerate(orientations):\n",
    "        tuning[ii] = mean_response[orientation==ori].mean()\n",
    "        stdev[ii] = mean_response[orientation==ori].std()\n",
    "    return tuning,stdev\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc53995",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #DFF0D8; \">\n",
    "\n",
    "<h2> Exercise 5a: Compute DSI</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22205c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets grab the same cell we were using before\n",
    "cell_idx = 17"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50908626",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #DFF0D8; \">\n",
    "\n",
    "Compute the dsi for this cell. Note that here we used the full session whereas this morning we used only the first half, which is why this number is not exactly the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea52408",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuning,_ = compute_tuning_curve(mean_response_all[:,cell_idx],orientation,orientations)\n",
    "observed_dsi = dsi(orientations,tuning) \n",
    "observed_dsi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c2997b",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #DFF0D8; \">\n",
    "\n",
    "Now lets shuffle responses, and recompute the DSI. How does it compare?\n",
    "    \n",
    "How you shuffle your data is an important part of what you will learn with any bootstrapping analysis. Here, we are randomly permuting cell responses, so that the statistics of the cell remain the same but the stimulus relationship is broken. However, randomly shifting reponses in time would have achieved the same effect, while preserving the cells temporal statistics as well. When choosing shuffling techniques, it is important to think about and understand what relationship(s) is/are being broken by your shuffling - these are what you will assess with your analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04834018",
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_responses = np.random.permutation(mean_response_all[:,cell_idx])\n",
    "shuffled_tuning,_ = compute_tuning_curve(shuffled_responses,orientation,orientations)\n",
    "shuffled_dsi = dsi(orientations,shuffled_tuning)\n",
    "shuffled_dsi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663f7478",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #DFF0D8; \">\n",
    "\n",
    "<h2> Exercise 5b: Build a distribution</h2>\n",
    "    \n",
    "Using the for loop below, build a distribtion of shuffled responses for this cell. Plot the histogram of these data, and compare this to the observed DSI value for this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5e3dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_shuffles= 10000\n",
    "shuffled_dsi = np.zeros(n_shuffles)\n",
    "for ii in range(n_shuffles):\n",
    "    None # delete this and fill in your code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0672b2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the histogram\n",
    "fig,ax = plt.subplots()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773eb9c4",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #DFF0D8; \">\n",
    "\n",
    "<h2> Exercise 5c: Significance test</h2>\n",
    "   \n",
    "    <p>\n",
    "Now that we have a distribtion, we can ask \"What is the probabliltiy that we would have observed this DSI value if there were not relationship to orientation tuning?\" This is, by definition, a p-value for our cells tuning. Like all pvalues, we can assess \"significance\" for our cell using a significance threshold. \n",
    "    </p>\n",
    "<p> \n",
    "Here, compute the p-value for this cell. Common signifcance thresholds are e.g. $p<.05$, $p<.01$. Did we pass?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c7819e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pval = 1-np.sum(shuffled_dsi<observed_dsi)/(n_shuffles+1)\n",
    "pval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2947ea7f",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #DFF0D8; \">\n",
    "\n",
    "<h2> Exercise 5d: Do this for the population</h2>\n",
    "    <p>\n",
    "        \n",
    "Now scale this analysis up for the population of cell in this recording session. For each cell, compute the observed DSI and its p-value. Using a signficance threshold of $p<.05$, plot the distributions of DSI for significant and non-significant cells.\n",
    "    </p>  \n",
    "    <p>\n",
    "    \n",
    "Note: One of the chalenges of bootstrapping is computational cost. We used 10,000 shuffles above, but this will take a few minutes if you do it for all your data. We recomend starting with 1000 shuffles here (but take a moment to think about what this might do to the result).\n",
    "    </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65b45c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ab7be25d",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #DFF0D8; \">\n",
    "\n",
    "<h2> Exercise 6: Running speed as a categorical variable.</h2>\n",
    " \n",
    "    <p>\n",
    "    Earlier we carried our regression model treating running speed as a continuous variable. But, the difference between running and not running might be far more consequential than changes in the value of running speed per se. This would motivate treating running speed as categorical variable, just as we have treated the stimulus orientations.  \n",
    "</p>   \n",
    "\n",
    "<p>\n",
    "Try repeating the regression analysis in this way. Do the results change? Is the answer sensitive to how we choose define our running threshold?\n",
    "</p>   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3114911",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "daa50317",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #DFF0D8; \">\n",
    "\n",
    "<h2> Exercise 7: Systematic evaluation of orientation- and running-modulation.</h2>\n",
    " \n",
    "    <p>\n",
    "    Our regression analysis focused on just one arbitrarily selected cell. Presumably, our scientific question did not pertain to this specific cell in this specific mouse <i>per se</i>, but more generally, cells belonging to the visual cortex of mice. Accordingly, any conclusions drawn on the basis of our analysis depend critically on the degree to which our selected cell is representative of the this broader population.  \n",
    "</p>   \n",
    "\n",
    "<p>\n",
    "In previous analyses, you've seen that things can look quite a bit different across different cells. For this exercise, try carrying out a more systematic investigation of tuning and running modulation of visual cortical cells. How  The goal is to obtain a better understanding of variability at the scale that our question concerns.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36f69ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d719dfc1",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #DFF0D8; \">\n",
    "\n",
    "<h2> Exercise 8: Constructing a generalized linear model (GLM).</h2>\n",
    " \n",
    "    <p>\n",
    "    We tried to spice up our linear model using polynomials -- still, this analysis assumes a particular distribution for our dependent variable (in particular, the residuals).  \n",
    "</p>   \n",
    "\n",
    "<p>\n",
    "An additional change for the sake of flexibility would be to equip our model with a <i>link function</i> via what's known as a <i> Genaralized </i> Linear Models (GLM). GLMs are routinely used to model spiking neural responses to stimuli, as spiking events are discrete, integer observations (counts) that are not Gaussian (but, rather <i> Poisson </i>) distributed.\n",
    "</p>\n",
    "\n",
    "<p>\n",
    "The GLM is defined as follows for some input $\\vec{x}_i$ and output $y_i$:\n",
    "</p>\n",
    "    \n",
    "<p>\n",
    "$P(y_i|\\vec{x}_i;\\vec{w}) = F(g^{-1}(\\vec{w}\\cdot\\vec{x}_i))$\n",
    "</p>\n",
    "    \n",
    "<p>\n",
    "Where $g$ is called the \"link function\", $F(m)$ represents some probability distribution with mean $m$, and $\\vec{w}$ is a vector of fitted parameters. These parameters are fit by finding the $\\vec{w}$ that maximizes $\\prod_{i=1}^N P(y_i|\\vec{x}_i;\\vec{w})$ for some dataset of $N$ samples. Note that when $g$ is the identity, and $F$ is the normal distribution with some fixed variance, this is just a linear regression problem.\n",
    "</p>\n",
    " \n",
    "<p>\n",
    "Fortunately, the sklearn package that we've been using so far also implements multiple GLMs with common link functions. These regressors can be imported from sklearn.linear_model as before, and they are equipped with the same functions (e.g., <i>fit</i>, <i>score</i>, and <i>predict</i>.\n",
    "</p>\n",
    "    \n",
    "<p>\n",
    "Below, try examining two different glm fits for the event data. Recall that above, we have taken the mean of the calcium event trace. How might the best link function differ if we used df/F instead? Compare model fits below.\n",
    "</p>\n",
    "    \n",
    "   <p>\n",
    "    <b> Note: </b> \"score\" will no longer correspond to $R^2$ once we've incorporated a (non-identity) link function! Hence, quantitative comparison across models is non-trivial. For now, though, try to create tuning curves based on these various linear models (i.e., linear regression as before, and GLMs with different link functions). How do these modeled tuning curves compare in appearance?\n",
    "   </p>\n",
    "    \n",
    "    <p>\n",
    "        <b> Hint: </b> The GLM regressors default to including a pretty strong regularization term ($L_2$ penalty). Start out by calling these regressors by explicitly setting this value to 0, as demonstrated in the next cell.\n",
    "   </p>\n",
    " \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e790bb8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
